{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 서빙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API 서빙 : 기능을 제공해준다, 모델 서빙, 모델 API 서빙, 모델 배포&서빙, 추론 서버를 만든다\n",
    "\n",
    "# API : Application Interface , 연결시켜줌\n",
    "# TCP 7 layer\n",
    "# 딥러닝의 API : REST API(HTTP통신,JSON데이터 형태) , 인터넷으로 통신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 웹 프레임 워크 REST API : Flask, Django, Fast-api, Pytriton(Nvidia, 제일 빠름, 추론 서버), 모바일로도 만들 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서빙 패턴 : '머신러닝 시스템 디자인 패턴'\n",
    "# 추론 속도가 오래걸린다 => 비동기 패턴 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web single Pattern : REST Server 안에 Model이 있는 구조\n",
    "# Preprocess-prediction Pattern : 전처리는 CPU가 추론은 GPU가 담당하게 하는 구조 (Pytriton)\n",
    "# Microservice vertical pattern : 데이터 1개마다 여러개의 모델을 돌려야할 때\n",
    "\n",
    "# 개념\n",
    "# Concurrent model execution : 멀티 스레딩 관점으로 추론하기, 유저가 다수 일 때, 비동기 처리로 모델을 추론하려면 메모리 공간이 있어야한다. 동시에 모델을 여러개 띄울 수 있어야함\n",
    "# Dynamic batching : 딥러닝의 특수성, 동시에 들어오는 요청을 배치 단위로 묶어주는 역할을 함.\n",
    "# Pytrion은 둘 다 지원 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서빙 종류\n",
    "\n",
    "# 직접 만드는 서빙FLask,Django,Fast-api ()\n",
    "\n",
    "# 만들어져 있는 서빙\n",
    "# tensorflowserve : tensorflow 전용 서빙도 있음 (C++추론, C++껍떼기)\n",
    "# torchserve : pytorch 전용 서빙 (C++추론, Java껍떼기)\n",
    "# triton inference learning\n",
    "# BentoML"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
