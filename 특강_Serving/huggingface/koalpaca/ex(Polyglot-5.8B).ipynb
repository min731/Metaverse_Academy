{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Koalpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U torch transformers tokenizers accelerate safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\koalpaca\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 663/663 [00:00<00:00, 663kB/s]\n",
      "c:\\Users\\user\\miniconda3\\envs\\koalpaca\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)fetensors.index.json: 100%|██████████| 36.8k/36.8k [00:00<?, ?B/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 926M/926M [00:11<00:00, 81.0MB/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 952M/952M [00:12<00:00, 73.6MB/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 948M/948M [00:12<00:00, 78.2MB/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 948M/948M [00:11<00:00, 79.9MB/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 952M/952M [00:43<00:00, 22.1MB/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 948M/948M [00:11<00:00, 81.0MB/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 948M/948M [00:11<00:00, 83.4MB/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 952M/952M [00:11<00:00, 83.4MB/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 948M/948M [00:11<00:00, 83.6MB/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 948M/948M [00:12<00:00, 78.8MB/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 952M/952M [00:11<00:00, 79.5MB/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 948M/948M [00:12<00:00, 77.4MB/s]\n",
      "Downloading (…)of-00013.safetensors: 100%|██████████| 515M/515M [00:06<00:00, 85.3MB/s]\n",
      "Downloading shards: 100%|██████████| 13/13 [03:03<00:00, 14.11s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 13/13 [00:00<00:00, 14.22it/s]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 116/116 [00:00<00:00, 115kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 210/210 [00:00<00:00, 210kB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.65M/1.65M [00:00<00:00, 5.72MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 185/185 [00:00<?, ?B/s] \n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "c:\\Users\\user\\miniconda3\\envs\\koalpaca\\lib\\site-packages\\transformers\\generation\\utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딥러닝은 인공지능 분야의 하나로서 연속된 계층을 이룬 신경망 네트워크를 이용합니다. 이를 통해 데이터의 복잡한 관계를 자동으로 학습하고, 새로운 데이터를 인식하고 예측할 수 있습니다. 예를 들어, 의료 분야에서는 암 진단, 심장 박동 등의 질환 진단에 딥러닝 기술을 사용합니다. 또한, 알파고와 같은 인공지능이 바둑 대회에서 인간 이긴 사례가 있으며, 이는 딥러닝의 기술을 이용한 것입니다. 최근에는 딥러닝을 활용한 인공지능이 발전하고 있으며, 이를 활용하여 의료, 금융, 물류 등 다양한 분야에서 예측 및 분석 등에 활용하고 있습니다. \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import pipeline, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "MODEL = 'beomi/KoAlpaca-Polyglot-5.8B'\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ").to(device=f\"cuda\", non_blocking=True)\n",
    "model.eval()\n",
    "\n",
    "pipe = pipeline(\n",
    "    'text-generation', \n",
    "    model=model,\n",
    "    tokenizer=MODEL,\n",
    "    device=0\n",
    ")\n",
    "\n",
    "def ask(x, context='', is_input_full=False):\n",
    "    ans = pipe(\n",
    "        f\"### 질문: {x}\\n\\n### 맥락: {context}\\n\\n### 답변:\" if context else f\"### 질문: {x}\\n\\n### 답변:\", \n",
    "        do_sample=True, \n",
    "        max_new_tokens=512,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        return_full_text=False,\n",
    "        eos_token_id=2,\n",
    "    )\n",
    "    print(ans[0]['generated_text'])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Koalpaca 로딩 시간 : \",end-start)\n",
    "\n",
    "\n",
    "ask(\"딥러닝이 뭐야?\")\n",
    "# 딥러닝은 인공신경망을 통해 입력과 출력 사이의 복잡한 관계를 학습하는 머신러닝의 한 분야입니다. \n",
    "# 이 기술은 컴퓨터가 인간의 학습 능력과 유사한 방식으로 패턴을 학습하도록 하며, 인간의 개입 없이도 데이터를 처리할 수 있는 기술입니다. \n",
    "# 최근에는 딥러닝을 활용한 인공지능 애플리케이션이 많이 개발되고 있습니다. 예를 들어, 의료 진단 애플리케이션에서는 딥러닝 기술을 활용하여 환자의 특징을 파악하고, \n",
    "# 이를 통해 빠르고 정확한 진단을 내리는 데 사용됩니다. 또한, 금융 분야에서는 딥러닝 기술을 활용하여 주가 예측 모형을 학습하는 데 사용되기도 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 요즘 날씨가 매우 추워졌습니다. 그러나 작년과는 다르게, 올해는 더 추운 것 같다는 느낌을 받습니다. 요즘 날씨를 보면, 한파가 자주 오는 것 같습니다. 이번 겨울은 많이 추울까요? \n",
      "\n",
      "실제로 이번 겨울은 작년보다 더 추울 것으로 예상됩니다. 그러나, 대부분의 추위는 겨울 동안 지속되지 않고, 일시적으로 낮아지는 경우가 많습니다. 따라서, 요즘 날씨가 춥다는 것은 그냥 느낌일 뿐이며, 실제로는 기온, 습도, 바람 등을 고려하여 체감 온도를 파악해야 합니다. \n",
      "\n",
      "체감 온도는 개인적인 차이와 환경의 영향을 받아 달라지기 때문에, 항상 정확한 측정 방법을 사용하여 체감 온도를 파악하는 것이 중요합니다. \n"
     ]
    }
   ],
   "source": [
    "ask(\"요즘 날씨 너무 춥지 않아?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 운영시간은 오전 9시부터 오후 6시까지입니다.\n",
      "2. 매장은 동일한 의미의 문장 10개를 나열합니다.\n",
      "\n",
      "위와 같은 간단한 문장들이 있습니다. 그러나 이 문장들은 더 세부적이고 전문적인 내용을 포함할 수 있습니다. 이러한 문장들을 작성할 때는 한 개의 단어를 길게 설명하는 대신, 여러 개의 단어를 포함하는 짧은 문장을 사용하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "ask(\"운영시간은 오전 9시부터 오후6시까지입니다. 와 동일한 의미의 문장 10개만 만들어줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02:20:45부터 03:20:45까지입니다.\n"
     ]
    }
   ],
   "source": [
    "ask(\"\"\"한 문장에 대해 동일한 의미의 문장 10개만 만들어주세요\n",
    "    \n",
    "    문장은 다음과 같습니다.\n",
    "\n",
    "    1.운영시간은 오전 9시부터 오후6시까지입니다. \n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 김밥은 하나에 1500원입니다.\n",
      "2. 과자 한 봉지에 500원입니다.\n",
      "3. 영화 한 편에 5,000원입니다.\n",
      "4. 지하철 한 구간에 500원입니다.\n",
      "5. 제주도 여행에는 비행기 값이 1만 원입니다.\n",
      "6. \"서울의 어느 곳에서도 볼 수 없는 경치입니다.\"는 하나의 문장입니다.\n",
      "7. 목욕탕의 가격은 맥반석에 따라 다릅니다.\n",
      "8. 호텔의 가격은 매우 비싸며, 예약하기 어려울 정도입니다.\n",
      "9. 마트에서 파는 과일의 가격은 매우 저렴합니다.\n",
      "10. 학교의 소풍 비용은 1인당 만 원입니다.\n"
     ]
    }
   ],
   "source": [
    "ask(\"\"\"한 문장에 대해 동일한 의미의 문장 10개만 만들어주세요\n",
    "    \n",
    "    문장은 다음과 같습니다.\n",
    "\n",
    "    1.김밥은 하나에 1500원입니다. \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래는 여자친구와 이별했을 때의 감정을 표현하는 10개의 문장입니다.\n",
      "1. \"너무 슬퍼요\"는 그 감정의 정도를 나타내며, 여자친구와의 관계에 대한 솔직한 표현입니다.\n",
      "2. \"내 마음속에는 네가 가득해요\"는 서로 사랑했던 순간과 추억을 떠올리며 다시 만나고 싶은 마음을 표현하는 문장입니다.\n",
      "3. \"가지마요\"는 이제 이별을 받아들이기 어렵지만, 그래도 이별은 싫다는 감정을 표현하는 문장입니다.\n",
      "4. \"내가 더 사랑해\"는 상대방을 이제는 보낼 수 없다는 결심을 하며 이별을 극복하겠다는 의지를 나타내는 문장입니다.\n",
      "5. \"저는 이별에 대한 아픔을 겪고 있어요\"는 치유받고 싶은 마음과 함께, 이별을 극복하겠다는 의지를 나타내는 문장입니다.\n",
      "6. \"저도 가끔은 이별을 원해요\"는 외로워하고 슬퍼하는 감정을 표현하는 문장입니다.\n",
      "7. \"다른 사람을 만나도 괜찮아요\"는 외로움을 느끼는 상황에서 벗어나 새로운 사람을 만나고 싶은 마음을 표현하는 문장입니다.\n",
      "8. \"당신이 내 곁에 있으면 나는 행복해요\"는 상대방을 열렬히 사랑했던 때와 그 감정을 떠올리며 다시 만나고 싶은 마음을 표현하는 문장입니다.\n",
      "9. \"너 때문에 힘들어\"는 이별의 고통과 함께 힘들어한다는 감정을 표현하는 문장입니다.\n",
      "10. \"저는 당신과 함께 갈 수 있다면 좋겠어요\"는 이별의 아쉬움과 절망감을 표현하는 문장입니다.\n"
     ]
    }
   ],
   "source": [
    "ask(\"\"\"다음 문장에 대해 동일한 의미의 문장 10개만 만들어주세요\\n여자친구랑 헤어져서 슬프겠구나.\\n정답. \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 차 세우는 곳에 주차하지 마세요.\n",
      "2. 주차할 장소에 차를 세우지 마세요.\n",
      "3. 차를 길에 주차하지 마세요.\n",
      "4. 불법 주차를 하지 마세요.\n",
      "5. 교차로, 보도 등에서 주차하지 마세요.\n",
      "6. 차를 타지 않은 경우, 차를 주차하지 마세요.\n",
      "7. 건물 주차장에 주차하지 마세요.\n",
      "8. 차를 내린 곳에 주차하지 마세요.\n",
      "9. 불법 주차 차량을 보면, 강력한 조치를 취하세요.\n",
      "10. 다른 사람의 차량을 불법 주차하지 않도록 하세요.\n"
     ]
    }
   ],
   "source": [
    "ask(\"\"\"다음 문장에 대해 동일한 의미의 문장 10개만 만들어주세요\\n주차 문의는 경비실로 연락바랍니다.\\n정답. \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"점심메뉴로 뭐 먹지?\"\n",
      "2. \"뭘 먹어야 잘 먹었다고 할까?\"\n",
      "3. \"오늘 점심으로 뭐 먹지?\"\n",
      "4. \"점심 때 뭐 먹지?\"\n",
      "5. \"오늘 점보러 가야하나?\"\n",
      "6. \"점심 때 뭐 먹지?\"\n",
      "7. \"오늘 아침 뭐 먹지?\"\n",
      "8. \"점심 때 뭐 먹지?\"\n",
      "9. \"오늘 밤 뭐 먹지?\"\n",
      "10. \"점심 때 뭐 먹지?\"\n"
     ]
    }
   ],
   "source": [
    "ask(\"\"\"다음 문장에 대해 동일한 의미의 문장 10개만 만들어주세요\\n점심 메뉴 추천해주세요.\\n정답. \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래는 한 문장으로 표현하는 방법입니다.\n",
      "       \n",
      "1. 점심 뭐 먹지?\n",
      "2. 오늘 점심 뭐 먹지?\n",
      "3. 오늘 점심으로 뭐 먹지?\n",
      "4. 오늘 아침으로 뭐 먹지?\n",
      "5. 아침 식사로 뭐 먹지?\n",
      "6. 점심 식사로 뭐 먹지?\n",
      "7. 오늘 저녁 식사로 뭐 먹지?\n",
      "8. 오늘 밤 간식으로 뭐 먹지?\n",
      "9. 오늘 아침 식사 대용으로 뭐 먹지?\n",
      "10. 오늘 점심 식사 대용으로 뭐 먹지?\n",
      "11. 오늘 저녁 식사 대용으로 뭐 먹지?\n",
      "12. 오늘 밤 간식으로 뭐 먹지?\n",
      "13. 오늘 아침 식사 대용으로 뭐 먹지?\n",
      "14. 오늘 저녁 식사 대용으로 뭐 먹지?\n",
      "15. 오늘 밤 간식으로 뭐 먹지?\n",
      "16. 오늘 아침 식사 대용으로 뭐 먹지?\n",
      "17. 오늘 저녁 식사 대용으로 뭐 먹지?\n",
      "18. 오늘 아침 식사 대용으로 뭐 먹지?\n",
      "19. 오늘 저녁 식사 대용으로 뭐 먹지?\n",
      "20. 오늘 아침 식사 대용으로 뭐 먹지?\n",
      "21. 오늘 저녁 식사 대용으로 뭐 먹지?\n",
      "22. 오늘 밤 간식으로 뭐 먹지?\n",
      "23. 오늘 아침 식사 대용으로 뭐 먹지?\n",
      "24. 오늘 저녁 식사 대용으로 뭐 먹지?\n",
      "25. 오늘 밤 간식으로 뭐 먹지?\n",
      "26. 오늘 아침 식사 대용으로 뭐 먹지?\n",
      "27. 오늘 저녁 식사 대용으로 뭐 먹지?\n",
      "28. 오늘 아침 식사 대용으로 뭐 먹지?\n",
      "29. 오늘 저녁 식사 대용으로 뭐 먹지?\n",
      "30. 오늘 아침 식사 대용으로 뭐 먹지?\n",
      "\n",
      "위 예시는 모두 같은 문장이며, 질문자님의 취향에 따라 다르게 표현하거나 추가할 수 있습니다. \n"
     ]
    }
   ],
   "source": [
    "ask(\"\"\"다음 문장에 대해 동일한 의미의 문장 30개만 만들어주세요\\n점심 메뉴 추천해주세요.\\n정답. \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\miniconda3\\envs\\koalpaca\\lib\\site-packages\\transformers\\pipelines\\base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음은 점심 메뉴에 대한 몇 가지 추천입니다.\n",
      "\n",
      "1. 김치볶음밥: 어디서든 어떤 메뉴로도 맛있게 만들 수 있는 메뉴입니다. 하지만 김치를 잘게 썰고 기름에 볶은 후 밥과 함께 먹으면 더욱 맛있습니다.\n",
      "\n",
      "2. 제육볶음: 제육을 볶으면서 야채와 함께 양념장을 넣어 끓여 먹으면 매콤한 맛을 즐길 수 있습니다.\n",
      "\n",
      "3. 두부김치: 두부와 김치를 볶아 먹는 메뉴로, 막걸리와 어울리는 안주나 밥 반찬으로도 좋습니다.\n",
      "\n",
      "4. 계란볶음밥: 계란과 파, 김치, 간장 등으로 간단하게 만들 수 있는 메뉴입니다.\n",
      "\n",
      "5. 김치찌개: 돼지고기, 김치, 양파 등으로 넣어 푹 끓인 김치찌개는 국물이 진하고 얼큰해 밥과 함께 먹으면 좋습니다.\n",
      "\n",
      "6. 된장찌개: 된장과 두부, 야채 등을 넣어 끓여 먹는 된장찌개는 한국 사람들이 가장 좋아하는 음식 중 하나입니다.\n",
      "\n",
      "7. 두부비빔밥: 두부와 야채, 김치, 간장 등으로 만든 비빔밥으로, 새콤한 초고추장과 함께 먹으면 더욱 맛있습니다.\n",
      "\n",
      "8. 라면: 라면 국물과 함께 야채, 계란, 김치 등을 넣어 끓인 후, 밥과 함께 먹으면 한 끼 식사로도 충분합니다.\n",
      "\n",
      "9. 카레: 카레는 밥과 야채, 고기 등을 볶아 끓인 후, 카레가루를 넣어 먹습니다. 일본의 대표적인 카레 메뉴인 '치킨커리'도 있습니다.\n",
      "\n",
      "10. 볶음밥: 고추장, 참치, 김치, 깻잎 등으로 볶아 만든 볶음밥은 간단하면서도 맛있는 한 끼 식사입니다.\n",
      "\n",
      "위 추천 메뉴를 참고하여 맛있는 식사를 만들어보세요. \n"
     ]
    }
   ],
   "source": [
    "ask(\"\"\"다음 문장에 대한 답변을 10개만 만들어주세요\\n점심 메뉴 추천해주세요.\\n정답. \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "ask(\"\"\"다음 문장에 대한 답변을 10개만 만들어주세요\\n활동적인 취미 추천좀해주세요.\\n정답. \n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "koalpaca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
